{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trec_results_per_number_of_target_per_source(rel_file, top_file, result_file):\n",
    "    gt = defaultdict(list)\n",
    "    with open(rel_file, 'r') as f:\n",
    "        for line in f:\n",
    "            gt[line.split(' ')[0]].append(line)\n",
    "    for i in range(1,11):\n",
    "        rel_file_i = rel_file + '_' + str(i)\n",
    "        with open(rel_file_i, 'w') as f:\n",
    "            for source in gt:\n",
    "                if len(gt[source]) == i:\n",
    "                    f.writelines(gt[source])\n",
    "        res_file = result_file + '_' + str(i)\n",
    "#         print('Processing', res_file)\n",
    "#         print(' '.join(['trec_eval -m all_trec', rel_file_i, top_file, '>', res_file,'2>&1']))\n",
    "        subprocess.call(' '.join(['trec_eval -m all_trec', rel_file_i, top_file, '>', res_file,'2>&1']), shell=True)\n",
    "#         print('Done')\n",
    "\n",
    "\n",
    "def clean_top_file(rel_file, top_file):\n",
    "    \"\"\"\n",
    "    Clean the top file such that only queries that exist in the\n",
    "    rel_file are in the top file\n",
    "    \"\"\"\n",
    "    keep_doc_set = set()\n",
    "    keep_lines = []\n",
    "    with open(rel_file, 'r') as f:\n",
    "        for line in f:\n",
    "            keep_doc_set.add(line.split(' ')[0])\n",
    "    with open(top_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.split(' ')[0] in keep_doc_set:\n",
    "                keep_lines.append(line)\n",
    "    with open(top_file, 'w') as f:\n",
    "        f.writelines(keep_lines)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../experiments/random_dblp_v10_10000_20_300_300_cosine_0_expand/fold_4\n",
      "Done\n",
      "Processing ../experiments/random_dblp_v10_10000_20_300_300_cosine_0_expand/fold_3\n",
      "Done\n",
      "Processing ../experiments/random_dblp_v10_10000_20_300_300_cosine_0_expand/fold_2\n",
      "Done\n",
      "Processing ../experiments/random_dblp_v10_10000_20_300_300_cosine_0_expand/fold_0\n",
      "Done\n",
      "Processing ../experiments/random_dblp_v10_10000_20_300_300_cosine_0_expand/fold_1\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand/fold_4\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand/fold_3\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand/fold_2\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand/fold_0\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand/fold_1\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand/fold_4\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand/fold_3\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand/fold_2\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand/fold_0\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand/fold_1\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand/fold_4\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand/fold_3\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand/fold_2\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand/fold_0\n",
      "Done\n",
      "Processing ../experiments/doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand/fold_1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "exp_folders = glob.glob('../experiments/*/')\n",
    "params = {}\n",
    "fold_results = []\n",
    "wrong_list = ['trec_eval: No queries with both results and rel', 'trec_eval.get_results: Cannot read results file']\n",
    "folds = []\n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[2]\n",
    "    if not os.path.exists(os.path.join(exp_folder, 'params.p')):\n",
    "        continue\n",
    "    with open(os.path.join(exp_folder, 'params.p'), 'rb') as params_file:\n",
    "        params[exp_name] = pickle.load(params_file)\n",
    "    fold_folders = glob.glob(os.path.join(exp_folder,'fold*'))\n",
    "    for fold_folder in fold_folders:\n",
    "        result_file = os.path.join(fold_folder, 'trec_results')\n",
    "        if not os.path.exists(result_file):\n",
    "            rel_file = os.path.join(fold_folder, 'trec_rel_file.tmp')\n",
    "            top_file = os.path.join(fold_folder, 'trec_top_file.tmp')\n",
    "            print('Processing', fold_folder)\n",
    "            clean_top_file(rel_file, top_file)\n",
    "            create_trec_results_per_number_of_target_per_source(rel_file, top_file, result_file)\n",
    "            subprocess.call(' '.join(['trec_eval -m all_trec', rel_file, top_file, '>', result_file,'2>&1']), shell=True)\n",
    "            print('Done')\n",
    "        result_files = glob.glob(os.path.join(fold_folder,'trec_result*'))\n",
    "        for rf in result_files:\n",
    "            with open(rf, 'r') as f:\n",
    "                ntps = rf.split('_')[-1]\n",
    "                first_line = f.readline()\n",
    "                if first_line[:47] in wrong_list:\n",
    "#                     print(first_line)\n",
    "#                     print(\"Error parsing: \" + rf)\n",
    "                    continue\n",
    "                f.seek(0)\n",
    "                if ntps == 'results':\n",
    "                    ntps = '0'\n",
    "                temp_result_df = pd.read_csv(f, header=None, delimiter=r\"\\s+\")\n",
    "                temp_result_df = temp_result_df.pivot(index=1, columns=0, values=2)\n",
    "                temp_result_df['ntps'] = ntps\n",
    "                folds.append(fold_folder.split('_')[-1])\n",
    "                temp_result_df.index = temp_result_df[['runid']] + '_ntps_' + ntps + \"_fold_\" + fold_folder.split('_')[-1] \n",
    "                fold_results.append(temp_result_df.copy())\n",
    "\n",
    "params_df = pd.DataFrame()\n",
    "fold_results = pd.concat(fold_results, axis=0)\n",
    "fold_results\n",
    "sel = np.logical_and(fold_results.columns != 'ntps',fold_results.columns != 'runid')\n",
    "# fold_results.loc[:, sel] = fold_results.loc[:, sel].apply(pd.to_numeric)\n",
    "fold_results['fold'] = folds\n",
    "params_df = pd.DataFrame.from_dict(params)\n",
    "unique_names = set([name[:-7] for name in fold_results.index])\n",
    "# print(unique_names)\n",
    "results = []\n",
    "for unique_name in unique_names:\n",
    "    res = fold_results[fold_results.index.str.contains(unique_name + '_')]['ntps'][0:1]\n",
    "#     print(res.values[0])\n",
    "    rest = fold_results[fold_results.index.str.contains(unique_name + '_')].drop('ntps', axis=1).apply(pd.to_numeric, errors='ignore').mean()\n",
    "    rest['ntps'] = int(res.values[0])\n",
    "    rest.name = '_'.join(unique_name.split('_')[:-2])\n",
    "#     print(rest)\n",
    "    rest = rest.to_frame()\n",
    "    res = pd.concat([rest.T, params_df.T,], axis=1, join='inner')\n",
    "#     print(res)\n",
    "    res.index = [unique_name]\n",
    "    results.append(res)\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "del results['fold']\n",
    "# results.rename(columns={'architecture':'algorithm'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>num_rel_ret</th>\n",
       "      <th>iterations</th>\n",
       "      <th>num_q</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>n_links</th>\n",
       "      <th>ntps</th>\n",
       "      <th>Rprec</th>\n",
       "      <th>ndcg_cut_100</th>\n",
       "      <th>map_cut_100</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand_ntps_0</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>14.8</td>\n",
       "      <td>20</td>\n",
       "      <td>883.4</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.00132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_dblp_v10_10000_10_300_300_cosine_0_expand_ntps_0</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10</td>\n",
       "      <td>883.4</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand_ntps_0</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>883.4</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.00148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aai_dblp_v10_10000_5_300_300_cosine_0_expand_ntps_0</th>\n",
       "      <td>aai</td>\n",
       "      <td>593.4</td>\n",
       "      <td>5</td>\n",
       "      <td>882.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01312</td>\n",
       "      <td>0.08182</td>\n",
       "      <td>0.02448</td>\n",
       "      <td>0.04728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_dblp_v10_10000_20_300_300_cosine_0_expand_ntps_0</th>\n",
       "      <td>random</td>\n",
       "      <td>12.6</td>\n",
       "      <td>20</td>\n",
       "      <td>883.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...  doc2vec-gensim   \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...             aai   \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...          random   \n",
       "\n",
       "                                                    num_rel_ret iterations  \\\n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...         14.8         20   \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...         13.2         10   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...         15.0          5   \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...        593.4          5   \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...         12.6         20   \n",
       "\n",
       "                                                    num_q n_docs n_links  \\\n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...  883.4  10000   13586   \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...  883.4  10000   13586   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...  883.4  10000   13586   \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...  882.6    NaN   13586   \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...  883.4    NaN   13586   \n",
       "\n",
       "                                                    ntps    Rprec  \\\n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...   0.0  0.00016   \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...   0.0  0.00030   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...   0.0  0.00028   \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...   0.0  0.01312   \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...   0.0  0.00016   \n",
       "\n",
       "                                                    ndcg_cut_100  map_cut_100  \\\n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...       0.00184      0.00040   \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...       0.00162      0.00038   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...       0.00180      0.00046   \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...       0.08182      0.02448   \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...       0.00168      0.00042   \n",
       "\n",
       "                                                    recip_rank  \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...     0.00132  \n",
       "doc2vec-gensim_dblp_v10_10000_10_300_300_cosine...     0.00140  \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...     0.00148  \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...     0.04728  \n",
       "random_dblp_v10_10000_20_300_300_cosine_0_expan...     0.00128  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.query('ntps == 0')[['algorithm', 'num_rel_ret', 'iterations','num_q','n_docs','n_links','ntps','Rprec','ndcg_cut_100','map_cut_100','recip_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>num_rel_ret</th>\n",
       "      <th>num_q</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>n_links</th>\n",
       "      <th>ntps</th>\n",
       "      <th>Rprec</th>\n",
       "      <th>ndcg_cut_100</th>\n",
       "      <th>map_cut_100</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aai_dblp_v10_10000_5_300_300_cosine_0_expand_ntps_6</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>41.2</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.03114</td>\n",
       "      <td>0.10448</td>\n",
       "      <td>0.03026</td>\n",
       "      <td>0.10180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_dblp_v10_10000_5_300_300_cosine_0_expand_ntps_6</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.00114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_dblp_v10_10000_20_300_300_cosine_0_expand_ntps_6</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>1.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.00358</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.00390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_0_expand_ntps_6</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>2.2</td>\n",
       "      <td>32.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>13586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.00200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         algorithm  \\\n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...  doc2vec-gensim   \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...  doc2vec-gensim   \n",
       "\n",
       "                                                         algorithm  \\\n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...  doc2vec-gensim   \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...  doc2vec-gensim   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...  doc2vec-gensim   \n",
       "\n",
       "                                                    num_rel_ret  num_q n_docs  \\\n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...         41.2   32.8  10000   \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...          2.0   32.8  10000   \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...          1.6   32.8  10000   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...          2.2   32.8  10000   \n",
       "\n",
       "                                                   n_links  ntps    Rprec  \\\n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...   13586   6.0  0.03114   \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...   13586   6.0  0.00000   \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...   13586   6.0  0.00088   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...   13586   6.0  0.00000   \n",
       "\n",
       "                                                    ndcg_cut_100  map_cut_100  \\\n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...       0.10448      0.03026   \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...       0.00332      0.00018   \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...       0.00358      0.00066   \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...       0.00396      0.00034   \n",
       "\n",
       "                                                    recip_rank  \n",
       "aai_dblp_v10_10000_5_300_300_cosine_0_expand_nt...     0.10180  \n",
       "random_dblp_v10_10000_5_300_300_cosine_0_expand...     0.00114  \n",
       "doc2vec-gensim_dblp_v10_10000_20_300_300_cosine...     0.00390  \n",
       "doc2vec-gensim_dblp_v10_10000_5_300_300_cosine_...     0.00200  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.query('ntps == 6').sort_values(by='ntps')[['algorithm', 'num_rel_ret','num_q','n_docs','n_links','ntps','Rprec','ndcg_cut_100','map_cut_100','recip_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scope_exp_name = \"doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True\" \n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[1]\n",
    "    if exp_name == scope_exp_name:\n",
    "        print(exp_name)\n",
    "        fold_folders = glob.glob(os.path.join(exp_folder,'fold*'))\n",
    "        for fold_folder in fold_folders:\n",
    "            gt_fname = os.path.join(fold_folder, 'trec_rel_file.tmp')\n",
    "            res_fname = os.path.join(fold_folder, 'trec_top_file.tmp')\n",
    "            gt_d = []\n",
    "            res_d = []\n",
    "            with open(gt_fname, 'r') as f:\n",
    "                gt_d.extend(f.readline().split(' ') for i in range(250))\n",
    "            with open(res_fname, 'r') as f:\n",
    "                res_d.extend(f.readline().split(' ') for i in range(250))\n",
    "            break\n",
    "        break\n",
    "gt = defaultdict(list)\n",
    "res = defaultdict(list)\n",
    "for line in gt_d:\n",
    "    gt[line[0]].append(line[2])\n",
    "for line in res_d:\n",
    "    res[line[0]].append(line[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trec Results \n",
    "\n",
    "### Standard\n",
    "\n",
    "\n",
    "| Abbreviation  \t| Description                                                               \t|\n",
    "|---------------\t|---------------------------------------------------------------------------\t|\n",
    "| num_ret       \t| Total number of documents retrieved over all queries                      \t|\n",
    "| num_rel       \t| Total number of relevant documents over all queries                       \t|\n",
    "| num_rel_ret   \t| Total number of relevant documents retrieved over all queries             \t|\n",
    "| map           \t| Mean Average Precision (MAP)                                              \t|\n",
    "| gm_ap         \t| Average Precision. Geometric Mean, q_score=log(MAX(map,.00001))           \t|\n",
    "| R-prec        \t| R-Precision (Precision after R (= num-rel for topic) documents retrieved) \t|\n",
    "| bpref         \t| Binary Preference, top R judged nonrel                                    \t|\n",
    "| recip_rank    \t| Reciprical rank of top relevant document                                  \t|\n",
    "| ircl_prn.0.00 \t| Interpolated Recall - Precision Averages at 0.00 recall                   \t|\n",
    "| ircl_prn.0.10 \t| Interpolated Recall - Precision Averages at 0.10 recall                   \t|\n",
    "| ircl_prn.0.20 \t| Interpolated Recall - Precision Averages at 0.20 recall                   \t|\n",
    "| ircl_prn.0.30 \t| Interpolated Recall - Precision Averages at 0.30 recall                   \t|\n",
    "| ircl_prn.0.40 \t| Interpolated Recall - Precision Averages at 0.40 recall                   \t|\n",
    "| ircl_prn.0.50 \t| Interpolated Recall - Precision Averages at 0.50 recall                   \t|\n",
    "| ircl_prn.0.60 \t| Interpolated Recall - Precision Averages at 0.60 recall                   \t|\n",
    "| ircl_prn.0.70 \t| Interpolated Recall - Precision Averages at 0.70 recall                   \t|\n",
    "| ircl_prn.0.80 \t| Interpolated Recall - Precision Averages at 0.80 recall                   \t|\n",
    "| ircl_prn.0.90 \t| Interpolated Recall - Precision Averages at 0.90 recall                   \t|\n",
    "| ircl_prn.1.00 \t| Interpolated Recall - Precision Averages at 1.00 recall                   \t|\n",
    "| P5            \t| Precision after 5 docs retrieved                                          \t|\n",
    "| P10           \t| Precision after 10 docs retrieved                                         \t|\n",
    "| P15           \t| Precision after 15 docs retrieved                                         \t|\n",
    "| P20           \t| Precision after 20 docs retrieved                                         \t|\n",
    "| P30           \t| Precision after 30 docs retrieved                                         \t|\n",
    "| P100          \t| Precision after 100 docs retrieved                                        \t|\n",
    "| P200          \t| Precision after 200 docs retrieved                                        \t|\n",
    "| P500          \t| Precision after 500 docs retrieved                                        \t|\n",
    "| P1000         \t| Precision after 1000 docs retrieved                                       \t|\n",
    "\n",
    "### All\n",
    "\n",
    "| Abbreviation                     \t| Description                                                                                                         \t|\n",
    "|----------------------------------\t|---------------------------------------------------------------------------------------------------------------------\t|\n",
    "| num_nonrel_judged_ret            \t| Total number of judged non-relevant documents retrieved over all queries                                            \t|\n",
    "| exact_prec                       \t| Exact Precision over retrieved set                                                                                  \t|\n",
    "| exact_recall                     \t| Exact Recall over retrieved set                                                                                     \t|\n",
    "| 11-pt_avg                        \t| Average over all 11 points of recall-precision graph                                                                \t|\n",
    "| 3-pt_avg                         \t| Average over 3 points of recall-precision graph                                                                     \t|\n",
    "| avg_doc_prec                     \t| Rel doc precision averaged over all relevant docs (NOT over topics)                                                 \t|\n",
    "| exact_relative_prec              \t| Exact relative precision                                                                                            \t|\n",
    "| avg_relative_prec                \t| Average relative precision                                                                                          \t|\n",
    "| exact_unranked_avg_prec          \t| Exact Unranked Average Precision                                                                                    \t|\n",
    "| exact_relative_unranked_avg_prec \t| Exact Relative Unranked Average Precision                                                                           \t|\n",
    "| map_at_R                         \t| Average Precision over first R docs retrieved                                                                       \t|\n",
    "| int_map                          \t| Interpolated Mean Average Precision                                                                                 \t|\n",
    "| exact_int_R_rcl_prec             \t| Exact R-based-interpolated-Precision                                                                                \t|\n",
    "| int_map_at_R                     \t| Average Interpolated Precision for first R docs retrieved                                                           \t|\n",
    "| bpref_allnonrel                  \t| Binary Preference, all judged nonrel                                                                                \t|\n",
    "| bpref_retnonrel                  \t| Binary Preference, all retrieved judged nonrel                                                                      \t|\n",
    "| bpref_topnonrel                  \t| Binary Preference, top 100 judged nonrel                                                                            \t|\n",
    "| bpref_top5Rnonrel                \t| Binary Preference, top 5R judged nonrel                                                                             \t|\n",
    "| bpref_top10Rnonrel               \t| Binary Preference, top 10R judged nonrel                                                                            \t|\n",
    "| bpref_top10pRnonrel              \t| Binary Preference, top 10 + R judged nonrel                                                                         \t|\n",
    "| bpref_top25pRnonrel              \t| Binary Preference, top 25 + R judged nonrel                                                                         \t|\n",
    "| bpref_top50pRnonrel              \t| Binary Preference, top 50 + R judged nonrel                                                                         \t|\n",
    "| bpref_top25p2Rnonrel             \t| Binary Preference, top 25 + 2*R judged nonrel                                                                       \t|\n",
    "| bpref_retall                     \t| Binary Preference, Only retrieved judged rel and nonrel                                                             \t|\n",
    "| bpref_5                          \t| Binary Preference, top 5 rel, top 5 nonrel                                                                          \t|\n",
    "| bpref_10                         \t| Binary Preference, top 10 rel, top 10 nonrel                                                                        \t|\n",
    "| bpref_num_all                    \t| Binary Preference, Number not retrieved before (all judged)                                                         \t|\n",
    "| bpref_num_ret                    \t| Binary Preference, Number retrieved after                                                                           \t|\n",
    "| bpref_num_correct                \t| Binary Preference, Number correct preferences                                                                       \t|\n",
    "| bpref_num_possible               \t| Binary Preference, Number possible correct_preferences                                                              \t|\n",
    "| old_bpref                        \t| Buggy Version 7.3. Binary Preference, top R judged nonrel                                                           \t|\n",
    "| old_bpref_top10pRnonrel          \t| Buggy Version 7.3. Binary Preference,top 10+R judged nonrel                                                         \t|\n",
    "| infAP                            \t| Inferred AP. Calculate AP using only a judged random sample of the pool, averaging in unpooled documents as nonrel. \t|\n",
    "| gm_bpref                         \t| Binary Preference, top R judged nonrel, Geometric Mean, q_score=log(MAX(bpref,.00001))                              \t|\n",
    "| rank_first_rel                   \t| Rank of top relevant document (0 if none)                                                                           \t|\n",
    "| recall5                          \t| Recall after 5 docs retrieved                                                                                       \t|\n",
    "| recall10                         \t| Recall after 10 docs retrieved                                                                                      \t|\n",
    "| recall15                         \t| Recall after 15 docs retrieved                                                                                      \t|\n",
    "| recall20                         \t| Recall after 20 docs retrieved                                                                                      \t|\n",
    "| recall30                         \t| Recall after 30 docs retrieved                                                                                      \t|\n",
    "| recall100                        \t| Recall after 100 docs retrieved                                                                                     \t|\n",
    "| recall200                        \t| Recall after 200 docs retrieved                                                                                     \t|\n",
    "| recall500                        \t| Recall after 500 docs retrieved                                                                                     \t|\n",
    "| recall1000                       \t| Recall after 1000 docs retrieved                                                                                    \t|\n",
    "| 0.20R-prec                       \t| R-based precision- precision after 0.20 * R docs retrieved                                                          \t|\n",
    "| 0.40R-prec                       \t| R-based precision- precision after 0.40 * R docs retrieved                                                          \t|\n",
    "| 0.60R-prec                       \t| R-based precision- precision after 0.60 * R docs retrieved                                                          \t|\n",
    "| 0.80R-prec                       \t| R-based precision- precision after 0.80 * R docs retrieved                                                          \t|\n",
    "| 1.00R-prec                       \t| R-based precision- precision after 1.00 * R docs retrieved                                                          \t|\n",
    "| 1.20R-prec                       \t| R-based precision- precision after 1.20 * R docs retrieved                                                          \t|\n",
    "| 1.40R-prec                       \t| R-based precision- precision after 1.40 * R docs retrieved                                                          \t|\n",
    "| 1.60R-prec                       \t| R-based precision- precision after 1.60 * R docs retrieved                                                          \t|\n",
    "| 1.80R-prec                       \t| R-based precision- precision after 1.80 * R docs retrieved                                                          \t|\n",
    "| 2.00R-prec                       \t| R-based precision- precision after 2.00 * R docs retrieved                                                          \t|\n",
    "| relative_prec5                   \t| Relative precision after 5 docs retrieved                                                                           \t|\n",
    "| relative_prec10                  \t| Relative precision after 10 docs retrieved                                                                          \t|\n",
    "| relative_prec15                  \t| Relative precision after 15 docs retrieved                                                                          \t|\n",
    "| relative_prec20                  \t| Relative precision after 20 docs retrieved                                                                          \t|\n",
    "| relative_prec30                  \t| Relative precision after 30 docs retrieved                                                                          \t|\n",
    "| relative_prec100                 \t| Relative precision after 100 docs retrieved                                                                         \t|\n",
    "| relative_prec200                 \t| Relative precision after 200 docs retrieved                                                                         \t|\n",
    "| relative_prec500                 \t| Relative precision after 500 docs retrieved                                                                         \t|\n",
    "| relative_prec1000                \t| Relative precision after 1000 docs retrieved                                                                        \t|\n",
    "| unranked_avg_prec5               \t| Unranked Average Precision after 5 docs retrieved                                                                   \t|\n",
    "| unranked_avg_prec10              \t| Unranked Average Precision after 10 docs retrieved                                                                  \t|\n",
    "| unranked_avg_prec15              \t| Unranked Average Precision after 15 docs retrieved                                                                  \t|\n",
    "| unranked_avg_prec20              \t| Unranked Average Precision after 20 docs retrieved                                                                  \t|\n",
    "| unranked_avg_prec30              \t| Unranked Average Precision after 30 docs retrieved                                                                  \t|\n",
    "| unranked_avg_prec100             \t| Unranked Average Precision after 100 docs retrieved                                                                 \t|\n",
    "| unranked_avg_prec200             \t| Unranked Average Precision after 200 docs retrieved                                                                 \t|\n",
    "| unranked_avg_prec500             \t| Unranked Average Precision after 500 docs retrieved                                                                 \t|\n",
    "| unranked_avg_prec1000            \t| Unranked Average Precision after 1000 docs retrieved                                                                \t|\n",
    "| relative_unranked_avg_prec5      \t| Relative Unranked Average Precision after 5 docs retrieved                                                          \t|\n",
    "| relative_unranked_avg_prec10     \t| Relative Unranked Average Precision after 10 docs retrieved                                                         \t|\n",
    "| relative_unranked_avg_prec15     \t| Relative Unranked Average Precision after 15 docs retrieved                                                         \t|\n",
    "| relative_unranked_avg_prec20     \t| Relative Unranked Average Precision after 20 docs retrieved                                                         \t|\n",
    "| relative_unranked_avg_prec30     \t| Relative Unranked Average Precision after 30 docs retrieved                                                         \t|\n",
    "| relative_unranked_avg_prec100    \t| Relative Unranked Average Precision after 100 docs retrieved                                                        \t|\n",
    "| relative_unranked_avg_prec200    \t| Relative Unranked Average Precision after 200 docs retrieved                                                        \t|\n",
    "| relative_unranked_avg_prec500    \t| Relative Unranked Average Precision after 500 docs retrieved                                                        \t|\n",
    "| relative_unranked_avg_prec1000   \t| Relative Unranked Average Precision after 1000 docs retrieved                                                       \t|\n",
    "| utility_1.0_-1.0_0.0_0.0         \t| Utility (a,b,c,d) Coefficients 1.0_-1.0_0.0_0.0                                                                     \t|\n",
    "| rcl_at_142_nonrel                \t| Recall averaged at X nonrel docs X= 142                                                                             \t|\n",
    "| fallout_recall_0                 \t| Fallout - Recall Averages- recall after 0 nonrel docs retrieved                                                     \t|\n",
    "| fallout_recall_14                \t| Fallout - Recall Averages- recall after 14 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_28                \t| Fallout - Recall Averages- recall after 28 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_42                \t| Fallout - Recall Averages- recall after 42 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_56                \t| Fallout - Recall Averages- recall after 56 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_71                \t| Fallout - Recall Averages- recall after 71 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_85                \t| Fallout - Recall Averages- recall after 85 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_99                \t| Fallout - Recall Averages- recall after 99 nonrel docs retrieved                                                    \t|\n",
    "| fallout_recall_113               \t| Fallout - Recall Averages- recall after 113 nonrel docs retrieved                                                   \t|\n",
    "| fallout_recall_127               \t| Fallout - Recall Averages- recall after 127 nonrel docs retrieved                                                   \t|\n",
    "| fallout_recall_142               \t| Fallout - Recall Averages- recall after 142 nonrel docs retrieved                                                   \t|\n",
    "| int_0.20R-prec                   \t| Interpolated R-based precision, after 0.20 * R docs retrieved                                                       \t|\n",
    "| int_0.40R-prec                   \t| Interpolated R-based precision, after 0.40 * R docs retrieved                                                       \t|\n",
    "| int_0.60R-prec                   \t| Interpolated R-based precision, after 0.60 * R docs retrieved                                                       \t|\n",
    "| int_0.80R-prec                   \t| Interpolated R-based precision, after 0.80 * R docs retrieved                                                       \t|\n",
    "| int_1.00R-prec                   \t| Interpolated R-based precision, after 1.00 * R docs retrieved                                                       \t|\n",
    "| int_1.20R-prec                   \t| Interpolated R-based precision, after 1.20 * R docs retrieved                                                       \t|\n",
    "| int_1.40R-prec                   \t| Interpolated R-based precision, after 1.40 * R docs retrieved                                                       \t|\n",
    "| int_1.60R-prec                   \t| Interpolated R-based precision, after 1.60 * R docs retrieved                                                       \t|\n",
    "| int_1.80R-prec                   \t| Interpolated R-based precision, after 1.80 * R docs retrieved                                                       \t|\n",
    "| int_2.00R-prec                   \t| Interpolated R-based precision, after 2.00 * R docs retrieved                                                       \t|\n",
    "| micro_prec                       \t| Total relevant retrieved documents / Total retrieved documents                                                      \t|\n",
    "| micro_recall                     \t| Total relevant retrieved documents / Total relevant documents                                                       \t|\n",
    "| micro_bpref                      \t| Total correct preferences / Total possible preferences                                                              \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Original ----\n",
      "146 Finite difference approximations of the second derivative in space appearing in, parabolic, incompletely parabolic systems of, and 2nd-order hyperbolic, partial differential equations are considered. If the solution is pointwise bounded, we prove that finite difference approximations of those classes of equations can be closed with two orders less accuracy at the boundary without reducing the global order of accuracy.This result is generalised to initial-boundary value problems with an mth-o\n",
      "-----    GT    ----\n",
      "-----  Found   ----\n",
      "> 352303 We present an efficient protocol for privacy-preserving evaluation of diagnostic programs, represented as binary decision trees or branching programs. The protocol applies a branching diagnostic program with classification labels in the leaves to the user's attribute vector. The user learns only the label assigned by the program to his vector; the diagnostic program itself remains secret. The program's owner does not learn anything. Our construction is significantly more efficient than th\n",
      "> 254284 The importance of Object-Oriented techniques is perhaps one of the most significant changes in programming over the last decade or more; in 1991, a team of three (Jacob Brickman, Michael J. Kent, and the author) began looking into what would be required to extend APL interpreters to provide native support for OO. At this writing, we have a great deal of agreement about overall architecture, some significant issues to resolve, an overall consensus that it is time to share these ideas, and \n",
      "> 4195 Feature selection is used for finding a feature subset that has the most discriminative information from the original feature set. In practice, since we do not know the classifier to be used after feature selection, it is desirable to find a feature subset that is universally effective for any classifier. Such a trial is called classifier-independent feature selection. In this study, we propose a novel classifier-independent feature selection method on the basis of the estimation of Bayes d\n",
      "> 101108 In this paper we are concerned with broadband wireless access via high altitude platform system, providing the Internet access and broadband multimedia services to passengers equipped with WLAN terminals connecting through a collective terminal mounted on the train. The main challenge in such scenario is the development of efficient and reliable radio interface for the broadband communication link in the mobile wireless access segment. We are focusing on performance analysis of the adapti\n",
      "> 601381 This paper deals with stochastic optimization of a discrete-event simulation model for the solution of a manufacturing system operation problem. Gradient estimates are obtained by the application of the infinitesimal perturbation analysis (IPA) technique. We begin with background material on stochastic approximation (SA) and the IPA technique, their potential value in finding optimal solutions to manufacturing system operation problems, and limitations concerning their applicability. Next\n"
     ]
    }
   ],
   "source": [
    "def raw_text(doc_name, limit=500):\n",
    "    with open('data.tmp/aminer_org_v1/texts.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            if line[:10].split(' ')[0] == doc_name:\n",
    "                if limit > 0:\n",
    "                    line = line[:limit]\n",
    "                return line\n",
    "doc_name = '146'\n",
    "print('----- Original ----')\n",
    "print(raw_text(doc_name))\n",
    "print('-----    GT    ----')\n",
    "for t in gt[doc_name]:\n",
    "    print('>', raw_text(t))\n",
    "print('-----  Found   ----')\n",
    "for t in res[doc_name][:5]:\n",
    "    print('>', raw_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bac25cc425f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_names' is not defined"
     ]
    }
   ],
   "source": [
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>architecture</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>concat</th>\n",
       "      <th>data</th>\n",
       "      <th>dist_measure</th>\n",
       "      <th>document_size</th>\n",
       "      <th>emb_size_d</th>\n",
       "      <th>emb_size_w</th>\n",
       "      <th>embedding_size_d</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>n_neg_samples</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>optimize</th>\n",
       "      <th>remove_docs_without_links</th>\n",
       "      <th>sample</th>\n",
       "      <th>seed</th>\n",
       "      <th>vocabulary_size</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>aminer_org_v1</td>\n",
       "      <td>cosine</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>170524</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>True</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>170524</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True             NaN   \n",
       "\n",
       "                                                      architecture batch_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim        128   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          random        128   \n",
       "\n",
       "                                                   concat           data  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...   True  aminer_org_v1   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True   True            NaN   \n",
       "\n",
       "                                                   dist_measure document_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...       cosine       34104.8   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          NaN       34104.8   \n",
       "\n",
       "                                                   emb_size_d emb_size_w  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...        300        300   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True        NaN        NaN   \n",
       "\n",
       "                                                   embedding_size_d  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...              300   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True              300   \n",
       "\n",
       "                                                       ...     learning_rate  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...     ...                 1   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True     ...                 1   \n",
       "\n",
       "                                                               loss_type  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  sampled_softmax_loss   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True  sampled_softmax_loss   \n",
       "\n",
       "                                                   n_neg_samples n_steps  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...            64  170524   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True            64  170524   \n",
       "\n",
       "                                                   optimize  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  Adagrad   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True  Adagrad   \n",
       "\n",
       "                                                   remove_docs_without_links  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...                      True   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True                       NaN   \n",
       "\n",
       "                                                   sample seed  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  50000    0   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True    NaN  NaN   \n",
       "\n",
       "                                                   vocabulary_size window_size  \n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...           50000           8  \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True           50000           8  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_precision</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_1_300_300_cosine</th>\n",
       "      <td>0.203961</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_5_300_300_cosine</th>\n",
       "      <td>0.926748</td>\n",
       "      <td>0.932935</td>\n",
       "      <td>5155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         average_precision  ndcg_at_10 n_steps\n",
       "pvdm_original_articles_1_300_300_cosine           0.203961    0.228228    1031\n",
       "pvdm_original_articles_5_300_300_cosine           0.926748    0.932935    5155"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_folders = glob.glob('experiments/*/')\n",
    "params = {}\n",
    "results = {}\n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[1]\n",
    "    if not os.path.exists(os.path.join(exp_folder, 'params.p')):\n",
    "        continue\n",
    "    with open(os.path.join(exp_folder, 'params.p'), 'rb') as params_file:\n",
    "        params[exp_name] = pickle.load(params_file)\n",
    "    with open(os.path.join(exp_folder, 'results.p'), 'rb') as results_file:\n",
    "        results[exp_name] = pickle.load(results_file)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "params_df = pd.DataFrame()\n",
    "for exp, result in results.items():\n",
    "    mean_result = pd.DataFrame.from_dict(result).mean()\n",
    "    mean_result.name=exp\n",
    "    result_df = result_df.append(mean_result)\n",
    "result_df = pd.concat([result_df, pd.DataFrame.from_dict(params).T], axis=1)\n",
    "result_df[['average_precision', 'ndcg_at_10', 'n_steps']].sort_values('n_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_precision</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>architecture</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>concat</th>\n",
       "      <th>data</th>\n",
       "      <th>dist_measure</th>\n",
       "      <th>document_size</th>\n",
       "      <th>emb_size_d</th>\n",
       "      <th>...</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>n_neg_samples</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>nsteps</th>\n",
       "      <th>optimize</th>\n",
       "      <th>prior_sample_size</th>\n",
       "      <th>vocabulary_size</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_aminer_org_v1_5_300_300_cosine</th>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>aminer_org_v1</td>\n",
       "      <td>cosine</td>\n",
       "      <td>111000</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>555000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_100001_300_300_cosine</th>\n",
       "      <td>0.677843</td>\n",
       "      <td>0.687516</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>100001</td>\n",
       "      <td>100001</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_5_100_100_cosine</th>\n",
       "      <td>0.675223</td>\n",
       "      <td>0.680724</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>5155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_5_300_300_cosine</th>\n",
       "      <td>0.673040</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>5155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_10000_300_300_cosine</th>\n",
       "      <td>0.649623</td>\n",
       "      <td>0.670708</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_1000_300_300_cosine</th>\n",
       "      <td>0.674012</td>\n",
       "      <td>0.685618</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_100_300_300_cosine</th>\n",
       "      <td>0.679642</td>\n",
       "      <td>0.689899</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_50000_300_300_cosine</th>\n",
       "      <td>0.639258</td>\n",
       "      <td>0.665104</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    average_precision  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                0.000702   \n",
       "doc2vec-gensim_original_articles_100001_300_300...           0.677843   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine            0.675223   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine            0.673040   \n",
       "pvdm_original_articles_10000_300_300_cosine                  0.649623   \n",
       "pvdm_original_articles_1000_300_300_cosine                   0.674012   \n",
       "pvdm_original_articles_100_300_300_cosine                    0.679642   \n",
       "pvdm_original_articles_50000_300_300_cosine                  0.639258   \n",
       "\n",
       "                                                    ndcg_at_10  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine         0.001029   \n",
       "doc2vec-gensim_original_articles_100001_300_300...    0.687516   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine     0.680724   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine     0.682589   \n",
       "pvdm_original_articles_10000_300_300_cosine           0.670708   \n",
       "pvdm_original_articles_1000_300_300_cosine            0.685618   \n",
       "pvdm_original_articles_100_300_300_cosine             0.689899   \n",
       "pvdm_original_articles_50000_300_300_cosine           0.665104   \n",
       "\n",
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine       doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine   doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine   doc2vec-gensim   \n",
       "pvdm_original_articles_10000_300_300_cosine                   pvdm   \n",
       "pvdm_original_articles_1000_300_300_cosine                    pvdm   \n",
       "pvdm_original_articles_100_300_300_cosine                     pvdm   \n",
       "pvdm_original_articles_50000_300_300_cosine                   pvdm   \n",
       "\n",
       "                                                   architecture batch_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine              pvdm        128   \n",
       "doc2vec-gensim_original_articles_100001_300_300...         pvdm        128   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine          pvdm        128   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine          pvdm        128   \n",
       "pvdm_original_articles_10000_300_300_cosine                pvdm        128   \n",
       "pvdm_original_articles_1000_300_300_cosine                 pvdm        128   \n",
       "pvdm_original_articles_100_300_300_cosine                  pvdm        128   \n",
       "pvdm_original_articles_50000_300_300_cosine                pvdm        128   \n",
       "\n",
       "                                                   concat               data  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine        True      aminer_org_v1   \n",
       "doc2vec-gensim_original_articles_100001_300_300...   True  original_articles   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine    True  original_articles   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine    True  original_articles   \n",
       "pvdm_original_articles_10000_300_300_cosine          True  original_articles   \n",
       "pvdm_original_articles_1000_300_300_cosine           True  original_articles   \n",
       "pvdm_original_articles_100_300_300_cosine            True  original_articles   \n",
       "pvdm_original_articles_50000_300_300_cosine          True  original_articles   \n",
       "\n",
       "                                                   dist_measure document_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine            cosine        111000   \n",
       "doc2vec-gensim_original_articles_100001_300_300...       cosine          1031   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine        cosine          1031   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine        cosine          1031   \n",
       "pvdm_original_articles_10000_300_300_cosine              cosine          1031   \n",
       "pvdm_original_articles_1000_300_300_cosine               cosine          1031   \n",
       "pvdm_original_articles_100_300_300_cosine                cosine          1031   \n",
       "pvdm_original_articles_50000_300_300_cosine              cosine          1031   \n",
       "\n",
       "                                                   emb_size_d     ...      \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine             300     ...       \n",
       "doc2vec-gensim_original_articles_100001_300_300...        300     ...       \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine         100     ...       \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine         300     ...       \n",
       "pvdm_original_articles_10000_300_300_cosine               300     ...       \n",
       "pvdm_original_articles_1000_300_300_cosine                300     ...       \n",
       "pvdm_original_articles_100_300_300_cosine                 300     ...       \n",
       "pvdm_original_articles_50000_300_300_cosine               300     ...       \n",
       "\n",
       "                                                   iterations learning_rate  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine               5             1   \n",
       "doc2vec-gensim_original_articles_100001_300_300...        NaN             1   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine           5             1   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine           5             1   \n",
       "pvdm_original_articles_10000_300_300_cosine               NaN             1   \n",
       "pvdm_original_articles_1000_300_300_cosine                NaN             1   \n",
       "pvdm_original_articles_100_300_300_cosine                 NaN             1   \n",
       "pvdm_original_articles_50000_300_300_cosine               NaN             1   \n",
       "\n",
       "                                                               loss_type  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine       sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine   sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine   sampled_softmax_loss   \n",
       "pvdm_original_articles_10000_300_300_cosine         sampled_softmax_loss   \n",
       "pvdm_original_articles_1000_300_300_cosine          sampled_softmax_loss   \n",
       "pvdm_original_articles_100_300_300_cosine           sampled_softmax_loss   \n",
       "pvdm_original_articles_50000_300_300_cosine         sampled_softmax_loss   \n",
       "\n",
       "                                                   n_neg_samples n_steps  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                 64  555000   \n",
       "doc2vec-gensim_original_articles_100001_300_300...            64  100001   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine             64    5155   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine             64    5155   \n",
       "pvdm_original_articles_10000_300_300_cosine                   64   10000   \n",
       "pvdm_original_articles_1000_300_300_cosine                    64    1000   \n",
       "pvdm_original_articles_100_300_300_cosine                     64     100   \n",
       "pvdm_original_articles_50000_300_300_cosine                   64   50000   \n",
       "\n",
       "                                                    nsteps optimize  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine          NaN  Adagrad   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  100001  Adagrad   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine      NaN  Adagrad   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine      NaN  Adagrad   \n",
       "pvdm_original_articles_10000_300_300_cosine          10000  Adagrad   \n",
       "pvdm_original_articles_1000_300_300_cosine            1000  Adagrad   \n",
       "pvdm_original_articles_100_300_300_cosine              100  Adagrad   \n",
       "pvdm_original_articles_50000_300_300_cosine          50000  Adagrad   \n",
       "\n",
       "                                                   prior_sample_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                    NaN   \n",
       "doc2vec-gensim_original_articles_100001_300_300...               NaN   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine                NaN   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine                NaN   \n",
       "pvdm_original_articles_10000_300_300_cosine                       10   \n",
       "pvdm_original_articles_1000_300_300_cosine                        10   \n",
       "pvdm_original_articles_100_300_300_cosine                         10   \n",
       "pvdm_original_articles_50000_300_300_cosine                       10   \n",
       "\n",
       "                                                   vocabulary_size window_size  \n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                50000           8  \n",
       "doc2vec-gensim_original_articles_100001_300_300...           50000           8  \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine            50000           8  \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine            50000           8  \n",
       "pvdm_original_articles_10000_300_300_cosine                  50000           8  \n",
       "pvdm_original_articles_1000_300_300_cosine                   50000           8  \n",
       "pvdm_original_articles_100_300_300_cosine                    50000           8  \n",
       "pvdm_original_articles_50000_300_300_cosine                  50000           8  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_folder = 'aminer_org_v1'\n",
    "rel_labels_fname = 'relevance_labels_' + data_folder + '.p'\n",
    "with open(rel_labels_fname, 'rb') as rel_lab_file:\n",
    "    _, _, _, tokenized, _, sorted_bm25_indices = pickle.load(rel_lab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "Computing BM25...\n",
      "Done computing bm25, compute average IDF...\n",
      "Done computing average IDF.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "output_fname='rel_labels.p'\n",
    "folder='original_articles'\n",
    "source_dict = {}  # maps article filename to source\n",
    "docs = []  # list with documents\n",
    "doc_names = []  # doc names with same index as docs\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data.tmp', folder)\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            docs.append(f.read())\n",
    "        doc_names.append(fname)\n",
    "\n",
    "tokenized = []\n",
    "for doc in docs:\n",
    "    tokens = [word for sent in nltk.sent_tokenize(doc) for word in nltk.word_tokenize(sent)]\n",
    "    tokenized.append(tokens)\n",
    "\n",
    "print(len(docs))\n",
    "print(\"Computing BM25...\")\n",
    "bm25 = gensim.summarization.bm25.BM25(tokenized)\n",
    "print(\"Done computing bm25, compute average IDF...\")\n",
    "average_idf = sum(map(lambda k: float(bm25.idf[k]), bm25.idf.keys())) / len(bm25.idf.keys())\n",
    "print(\"Done computing average IDF.\")\n",
    "bm25_scores = []\n",
    "sorted_bm25_indices = []\n",
    "len_tokenized = len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 517 Definition of eligible capital By 31 December 2014 the Commission shall review and report on the appropriateness of the definition of eligible capital being applied for the purposes of Title III of Part Two and Part Four and shall submit that report to the European Parliament and the Council , and , if appropriate , a legislative proposal .\n",
      "867\n"
     ]
    }
   ],
   "source": [
    "doc = tokenized[500]\n",
    "print(' '.join(doc))\n",
    "temp_bm25_scores = bm25.get_scores(doc, average_idf)\n",
    "temp_bm25_scores = temp_bm25_scores\n",
    "sorted_indices = sorted(range(len(temp_bm25_scores)), key=lambda x: temp_bm25_scores[x], reverse=True)\n",
    "# print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import math\n",
    "\n",
    "class BM25 :\n",
    "    def __init__(self, fn_docs) :\n",
    "        self.dictionary = corpora.Dictionary()\n",
    "        self.doc_names = []\n",
    "        self.source_dict = {}\n",
    "        self.DF = {}\n",
    "        self.DocTF = []\n",
    "        self.DocIDF = {}\n",
    "        self.N = 0\n",
    "        self.DocAvgLen = 0\n",
    "        self.fn_docs = fn_docs\n",
    "        self.DocLen = []\n",
    "        self.buildDictionary()\n",
    "        self.TFIDF_Generator()\n",
    "\n",
    "    def buildDictionary(self) :\n",
    "        data = []\n",
    "#         for line in file(self.fn_docs) :\n",
    "#             data.append(line.strip().split(self.delimiter))\n",
    "        data_path = os.path.join(os.getcwd(), 'data.tmp', self.fn_docs)\n",
    "        for subdir, dirs, files in os.walk(data_path):\n",
    "            files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "            for file in files:\n",
    "                path = os.path.join(subdir, file)\n",
    "                folder_name = subdir.split(os.path.sep)[-1]\n",
    "                fname = file[:-4]\n",
    "                self.source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "                with open(path, 'r', encoding='utf8') as f:\n",
    "                    data.append([word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)])\n",
    "                self.doc_names.append(fname)\n",
    "        self.dictionary.add_documents(data)\n",
    "\n",
    "    def TFIDF_Generator(self, base=math.e) :\n",
    "        docTotalLen = 0\n",
    "        data_path = os.path.join(os.getcwd(), 'data.tmp', self.fn_docs)\n",
    "        for subdir, dirs, files in os.walk(data_path):\n",
    "            files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "            for file in files:\n",
    "                path = os.path.join(subdir, file)\n",
    "                with open(path, 'r', encoding='utf8') as f:\n",
    "                    doc = [word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)]\n",
    "                docTotalLen += len(doc)\n",
    "                self.DocLen.append(len(doc))\n",
    "                bow = dict([(term, freq*1.0/len(doc)) for term, freq in self.dictionary.doc2bow(doc)])\n",
    "                for term, tf in bow.items() :\n",
    "                    if term not in self.DF :\n",
    "                        self.DF[term] = 0\n",
    "                    self.DF[term] += 1\n",
    "                self.DocTF.append(bow)\n",
    "                self.N = self.N + 1\n",
    "        for term in self.DF:\n",
    "            self.DocIDF[term] = math.log((self.N - self.DF[term] +0.5) / (self.DF[term] + 0.5), base)\n",
    "        self.DocAvgLen = docTotalLen / self.N\n",
    "\n",
    "    def BM25Score(self, Query=[], k1=1.5, b=0.75) :\n",
    "        query_bow = self.dictionary.doc2bow(Query)\n",
    "        scores = []\n",
    "        for idx, doc in enumerate(self.DocTF) :\n",
    "            commonTerms = set(dict(query_bow).keys()) & set(doc.keys())\n",
    "            tmp_score = []\n",
    "            doc_terms_len = self.DocLen[idx]\n",
    "            for term in commonTerms :\n",
    "                upper = (doc[term] * (k1+1))\n",
    "                below = ((doc[term]) + k1*(1 - b + b*doc_terms_len/self.DocAvgLen))\n",
    "                tmp_score.append(self.DocIDF[term] * upper / below)\n",
    "            scores.append(sum(tmp_score))\n",
    "        return scores\n",
    "\n",
    "    def TFIDF(self) :\n",
    "        tfidf = []\n",
    "        for doc in self.DocTF :\n",
    "            doc_tfidf  = [(term, tf*self.DocIDF[term]) for term, tf in doc.items()]\n",
    "            doc_tfidf.sort()\n",
    "            tfidf.append(doc_tfidf)\n",
    "        return tfidf\n",
    "\n",
    "    def Items(self) :\n",
    "        # Return a list [(term_idx, term_desc),]\n",
    "        items = self.dictionary.items()\n",
    "        items.sort()\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "output_fname='rel_labels.p'\n",
    "folder='aminer_org_v1'\n",
    "source_dict = {}  # maps article filename to source\n",
    "docs = []  # list with documents\n",
    "doc_names = []  # doc names with same index as docs\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data.tmp', folder)\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            docs.append(f.read())\n",
    "        doc_names.append(fname)\n",
    "\n",
    "tokenized = []\n",
    "for doc in docs:\n",
    "    tokens = [word for sent in nltk.sent_tokenize(doc) for word in nltk.word_tokenize(sent)]\n",
    "    tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_docs = 'aminer_org_v1'\n",
    "bm25 = BM25(fn_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91283\n",
      "[91283, 6339, 72175, 33383, 57814, 109712, 19367, 94624, 35338, 22166]\n",
      "\n",
      "Original text:\n",
      "\n",
      "Dynamically managing the communication-parallelism trade-off in future clustered processors Clustered microarchitectures are an attractive alternative to large monolithic superscalar designs due to their potential for higher clock rates in the face of increasingly wire-delay-constrained process technologies . As increasing transistor counts allow an increase in the number of clusters , thereby allowing more aggressive use of instruction-level parallelism ( ILP ) , the inter-cluster communication increases as data values get spread across a wider area . As a result of the emergence of this trade-off between communication and parallelism , a subset of the total on-chip clusters is optimal for performance . To match the hardware to the application 's needs , we use a robust algorithm to dynamically tune the clustered architecture . The algorithm , which is based on program metrics gathered at periodic intervals , achieves an 11 % performance improvement on average over the best statically defined architecture . We also show that the use of additional hardware and reconfiguration at basic block boundaries can achieve average improvements of 15 % . Our results demonstrate that reconfiguration provides an effective solution to the communication and parallelism trade-off inherent in the communication-bound processors of the future .\n",
      "\n",
      "Top 5:\n",
      "\n",
      "Dynamically managing the communication-parallelism trade-off in future clustered processors Clustered microarchitectures are an attractive alternative to large monolithic superscalar designs due to their potential for higher clock rates in the face of increasingly wire-delay-constrained process technologies . As increasing transistor counts allow an increase in the number of clusters , thereby allowing more aggressive use of instruction-level parallelism ( ILP ) , the inter-cluster communication increases as data values get spread across a wider area . As a result of the emergence of this trade-off between communication and parallelism , a subset of the total on-chip clusters is optimal for performance . To match the hardware to the application 's needs , we use a robust algorithm to dynamically tune the clustered architecture . The algorithm , which is based on program metrics gathered at periodic intervals , achieves an 11 % performance improvement on average over the best statically defined architecture . We also show that the use of additional hardware and reconfiguration at basic block boundaries can achieve average improvements of 15 % . Our results demonstrate that reconfiguration provides an effective solution to the communication and parallelism trade-off inherent in the communication-bound processors of the future . \n",
      "--------------------\n",
      "\n",
      "Emergent process design No abstract available \n",
      "--------------------\n",
      "\n",
      "Guest Editors ' Introduction : High-Performance Reconfigurable Computing High-performance reconfigurable computers have the potential to exploit coarse-grained functional parallelism as well as fine-grained instruction-level parallelism through direct hardware execution on FPGAs . \n",
      "--------------------\n",
      "\n",
      "Agile software reuse recommender No abstract available \n",
      "--------------------\n",
      "\n",
      "Self-assessment procedure XVII A self-assessment procedure dealing with ACM \n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect(index):\n",
    "    print(index)\n",
    "    Query = tokenized[index]\n",
    "    scores = bm25.BM25Score(Query)\n",
    "    sorted_indices = sorted(range(len(scores)), key=lambda x: scores[x], reverse=True)\n",
    "    print(sorted_indices[:10])\n",
    "    print('\\nOriginal text:\\n')\n",
    "    print(' '.join(tokenized[index][:300]))\n",
    "    print('\\nTop 5:\\n')\n",
    "    for i in range(5):\n",
    "        print(' '.join(tokenized[sorted_indices[i]]),'\\n--------------------\\n')\n",
    "\n",
    "index = np.random.randint(len(tokenized))\n",
    "inspect(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandervansomeren/Documents/Studie/Msc_AI/Thesis/regulatory tracker/doc2vec_pipeline/data.tmp/original_articles\n"
     ]
    }
   ],
   "source": [
    "fn_docs = 'original_articles'\n",
    "\n",
    "\n",
    "data = []\n",
    "data_path = os.path.join(os.getcwd(), 'data.tmp', fn_docs)\n",
    "print(data_path)\n",
    "doc_names=[]\n",
    "dictionary=corpora.Dictionary()\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            data.append([word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)])\n",
    "        doc_names.append(fname)\n",
    "dictionary.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow() missing 1 required positional argument: 'document'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-5f98ec8bc765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow() missing 1 required positional argument: 'document'"
     ]
    }
   ],
   "source": [
    "dictionary.doc2bow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regulatory_tracker]",
   "language": "python",
   "name": "conda-env-regulatory_tracker-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nbpresent": {
   "slides": {
    "7bdfc0fc-9cb9-4774-aaa5-ec1059c174ed": {
     "id": "7bdfc0fc-9cb9-4774-aaa5-ec1059c174ed",
     "prev": "8b4c6ddd-df51-456d-b79a-2ca76c61163f",
     "regions": {
      "b4df9567-5fa8-45a1-b5fc-1330bfafb954": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4f833753-0a8c-48d8-b5f1-6b8660996bb6",
        "part": "whole"
       },
       "id": "b4df9567-5fa8-45a1-b5fc-1330bfafb954"
      }
     }
    },
    "8b4c6ddd-df51-456d-b79a-2ca76c61163f": {
     "id": "8b4c6ddd-df51-456d-b79a-2ca76c61163f",
     "prev": null,
     "regions": {}
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
